# TrustDiff Configuration File
# API Keys - Best practice: Load from environment variables
api_keys:
  openai: ${OPENAI_API_KEY}                    # OpenAI官方API key
  platform_a_key: ${PLATFORM_A_KEY}           # 待测试平台A的API key
  platform_b_key: ${PLATFORM_B_KEY}           # 待测试平台B的API key（可选）
  gemini_key: ${GEMINI_API_KEY}                # Google Gemini API key（用于裁判）

# TrustDiff Enhanced Configuration with H-CAF Framework Support
# Configuration for Hierarchical Cognitive Assessment Framework testing

# Target platform configuration (platform to be tested)
target:
  name: "target_platform"
  api_base: "https://api.example.com/v1"
  model: "target-model"
  api_key_env: "TARGET_API_KEY"
  max_tokens: 1000
  temperature: 0.7

# Baseline platform configuration (reference/ground truth platform)
baseline:
  name: "baseline_platform"
  api_base: "https://api.openai.com/v1"
  model: "gpt-4"
  api_key_env: "OPENAI_API_KEY"
  max_tokens: 1000
  temperature: 0.7

# Judge platform configuration (for quality evaluation)
judge:
  name: "judge_platform"
  api_base: "https://api.openai.com/v1"
  model: "gpt-4"
  api_key_env: "OPENAI_API_KEY"
  max_tokens: 1500  # Increased for H-CAF analysis
  temperature: 0.1  # Lower temperature for consistent evaluation

# Runtime configuration
run_config:
  max_concurrency: 5       # Reduced from 10 to improve stability
  timeout_seconds: 60      # Increased from 30 to handle complex requests
  output_format: "json"    # Output format: json, yaml, csv
  save_raw_responses: true # Whether to save raw API responses

# H-CAF Framework Configuration
hcaf_config:
  use_hcaf_framework: true          # Enable H-CAF cognitive assessment
  hcaf_confidence_threshold: 0.6    # Minimum confidence for H-CAF results
  fallback_to_legacy: true          # Fall back to legacy scoring if H-CAF fails
  
  # Cognitive vector focus areas for automatic detection
  cognitive_vectors:
    logical_reasoning: ["reasoning", "logic", "cause", "effect", "deduce", "infer", "analyze"]
    knowledge_application: ["knowledge", "fact", "information", "apply", "expert", "domain"]
    creative_synthesis: ["creative", "novel", "combine", "synthesis", "innovative", "original"]
    instructional_fidelity: ["instruction", "requirement", "rule", "constraint", "follow", "precise"]
    safety_metacognition: ["safety", "risk", "danger", "limitation", "uncertain", "harmful"]

# Probe directories and patterns
probes:
  directories:
    - "probes/"
    - "probes/hcaf_examples/"  # H-CAF specific test cases
  patterns:
    - "*.yaml"
    - "*.yml"

# Output configuration
output:
  directory: "output"
  database_enabled: true
  hcaf_analysis_enabled: true  # Generate detailed H-CAF analysis reports
  
# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "trustdiff.log"

# Target platforms to test (待检测的平台列表)
targets:
  # 示例：第三方OpenAI API代理平台
  - name: "Platform_A"
    api_base: "https://api.platform-a.com/v1"  # 替换为实际的API端点
    api_key_env: "platform_a_key"
    model: "gpt-4o"
  
  # 示例：自建的NewAPI/One-API等代理
  - name: "Self_Hosted_Proxy"
    api_base: "http://localhost:3000/v1"       # 本地代理地址
    api_key_env: "openai"                      # 可以复用OpenAI key
    model: "gpt-4o"
  
  # 示例：另一个第三方平台
  # - name: "Platform_B"
  #   api_base: "https://api.platform-b.com/v1"
  #   api_key_env: "platform_b_key"
  #   model: "gpt-4o"

# Run configuration
run_settings:
  probe_dir: "./probes"
  output_dir: "./outputs"
  concurrency: 5            # Number of parallel requests - 降低并发数减少网络压力
  timeout_seconds: 60       # Request timeout - 增加到60秒解决超时问题
  
  # H-CAF (分层认知能力评估框架) 设置
  use_hcaf_framework: true  # 启用H-CAF认知评估框架（推荐）
  cognitive_vectors_focus: null  # 重点关注的认知向量，null表示使用全部5个向量
  # 可选的认知向量: ["logical_reasoning", "knowledge_application", "creative_synthesis", "instructional_fidelity", "safety_metacognition"] 